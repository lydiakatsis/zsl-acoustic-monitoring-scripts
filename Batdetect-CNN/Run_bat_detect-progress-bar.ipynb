{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1662ae82-a312-4b11-a0fe-b9cf0f13480a",
   "metadata": {},
   "source": [
    "## Run bat detect on bucket files using Vertex AI ##\n",
    "\n",
    "GPU will automatically be used if select the resources when making the notebook\n",
    "\n",
    "Run time is approx 17 seconds per minute of audio with 4 CPUS and no GPU\n",
    "Run time is 6 seconds per minute of audio with 8 CPUS and 1 GPU\n",
    "\n",
    "\n",
    "## Instructions ##\n",
    " \n",
    "1. The only part of this script you will need to change is the directory of audio files and results folders.\n",
    "    * Change these file paths to the paths of your input folder and output folder within the Bucket.\n",
    "2. Once you have set the file directories, select Run -> Run all cells from the menu above.\n",
    "3. The final argument should shut down the instance when this has finished, however if there is an error at some point or the script becomes unresponsive, then this argument will not be executed, so you should check in on progress of script periodically.\n",
    "4. If scripts becomes unresponsive before it has completed, then restart the kernel. The script is unresponsive if the boxes next to the current command changes from [*] / [number] to [ ] \n",
    "\n",
    "\n",
    "**Source of potential errors:** \n",
    "* If you have multiple kernels running in this instance, then GPU allocation may be disrupted and it will throw errors - make sure there is only one notebook open when running this script. You can view kernels on the left, with the Stop Icon that is below the folder browser. Shut down all the kernels except for this script.\n",
    "\n",
    "* The notebook may become unresponsive after running for a long time - you will have to restart notebook and code again. It will resume classifying from where it left off.\n",
    "\n",
    "* Some files will not be analysed as there will be several 0MB files recorded by the AudioMoth, so don't be concerned if some files can't be analysed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3b6af3-085f-41df-b6e7-b39e6493f6dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mounted\n",
      "2022/12/12 16:39:50.706569 Start gcsfuse/0.41.8 (Go version go1.18.4) for app \"\" using mount point: /home/jupyter/gcs_outputs\n",
      "2022/12/12 16:39:50.719365 Opening GCS connection...\n",
      "2022/12/12 16:39:50.792784 Mounting file system \"acoustic-processing-outputs\"...\n",
      "daemonize.Run: readFromProcess: sub-process: mountWithArgs: mountWithConn: Mount: mount: running /usr/bin/fusermount: exit status 1\n",
      "mounted\n",
      "2022/12/12 16:39:50.927539 Start gcsfuse/0.41.8 (Go version go1.18.4) for app \"\" using mount point: /home/jupyter/gcs_raw\n",
      "2022/12/12 16:39:50.939939 Opening GCS connection...\n",
      "2022/12/12 16:39:51.010956 Mounting file system \"acoustic-data-raw\"...\n",
      "daemonize.Run: readFromProcess: sub-process: mountWithArgs: mountWithConn: Mount: mount: running /usr/bin/fusermount: exit status 1\n"
     ]
    }
   ],
   "source": [
    "# mount buckets\n",
    "!mountpoint -q /home/jupyter/gcs_outputs && echo \"mounted\" || mkdir -p gcs_outputs; gcsfuse --implicit-dirs --rename-dir-limit=100 --disable-http2 --max-conns-per-host=100 \"acoustic-processing-outputs\" \"/home/jupyter/gcs_outputs\"\n",
    "!mountpoint -q /home/jupyter/gcs_raw && echo \"mounted\" || mkdir -p gcs_raw; gcsfuse --implicit-dirs --rename-dir-limit=100 --disable-http2 --max-conns-per-host=100 \"acoustic-data-raw\" \"/home/jupyter/gcs_raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8c69284-2e8f-45d9-b9b8-c619cb856343",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scripts are downloaded\n"
     ]
    }
   ],
   "source": [
    "# download scripts if not already there\n",
    "![ -d \"/home/jupyter/batdetect_v3-master\" ] && echo \"Scripts are downloaded\" || gcloud storage cp -r 'gs://data-processing-scripts/batdetect_v3-master' ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d5935a1-9cbe-499a-b935-2f8338044d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: librosa\n",
      "Version: 0.8.1\n",
      "Summary: Python module for audio and music processing\n",
      "Home-page: https://librosa.org\n",
      "Author: Brian McFee, librosa development team\n",
      "Author-email: brian.mcfee@nyu.edu\n",
      "License: ISC\n",
      "Location: /opt/conda/lib/python3.7/site-packages\n",
      "Requires: audioread, decorator, joblib, numba, numpy, packaging, pooch, resampy, scikit-learn, scipy, soundfile\n",
      "Required-by: \n",
      "librosa installed\n"
     ]
    }
   ],
   "source": [
    "!pip show librosa && echo \"librosa installed\" || pip install librosa==0.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7046ca69-abf0-4fee-a5e3-258ffa03ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = '/home/jupyter/batdetect_v3-master'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5867404-1838-4138-a11f-e7507c7e165c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import os\n",
    "import glob\n",
    "import config\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bat_detect.utils.detector_utils as du\n",
    "import bat_detect.utils.audio_utils as au\n",
    "import bat_detect.utils.plot_utils as viz\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1578a0fe-c7f9-40bd-bf14-22a522ab787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02fb9425-92a2-439a-9ed9-0a69b2bb6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the arguments\n",
    "args = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167dc99e-9736-422d-be05-d77ad7903b00",
   "metadata": {},
   "source": [
    "## Change input and output directories here: ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5187368a-8f0b-4fa0-9480-b596f4b10029",
   "metadata": {},
   "source": [
    "#Â Set folders for input (i.e. sound folders to analyse) and output #\n",
    "\n",
    "These folders will be mounted on the left, so will start with '/home/jupyter/' but they are accessing files from the Google Cloud Bucket that you mounted. Make sure input_folder is the raw audio folder, and the results_folder is within gcs_outputs.\n",
    "\n",
    "**All you need to change from below is 'trial_data_2021' on both lines to the new folder.**\n",
    "\n",
    "# &darr; &darr; &darr; &darr; &darr; &darr; &darr; &darr; &darr; &darr; &darr; &darr; #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "713bd81c-351d-4d29-a5fa-7be709711b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "args['ann_dir'] = \"/home/jupyter/gcs_outputs/trial_data_2021/batdetect/\"\n",
    "args['audio_dir'] = \"/home/jupyter/gcs_raw/trial_data_2021/bat-config/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7606a-bc5a-430a-9938-8075aa60dd44",
   "metadata": {},
   "source": [
    "# &uarr; &uarr; &uarr; &uarr; &uarr; &uarr; &uarr; &uarr; &uarr; &uarr; &uarr; &uarr; #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b7f7089-dbbe-4a2e-8086-03453bc32cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Leave these as is\n",
    "args['detection_threshold'] = 0.3\n",
    "args['time_expansion_factor'] = 1\n",
    "args['model_url'] = config.MODEL_URL\n",
    "args['model_path'] = os.path.join('models', os.path.basename(args['model_url']))\n",
    "\n",
    "args['cnn_features'] = False\n",
    "args['spec_features'] = False\n",
    "args['quiet'] = True\n",
    "args['save_preds_if_empty'] = False\n",
    "args['spec_slices'] = False\n",
    "args['chunk_size'] = 3\n",
    "args['save_preds_if_empty'] = True\n",
    "\n",
    "\n",
    "path = '/home/jupyter/batdetect_v3-master'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58906a88-5512-45f1-90a3-ab6d9769ca54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9728b3e5f24d9daa8f881bba04250e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0     Copy of 20220325_210000.WAV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to_/home/jupyter/gcs_outputs/trial_data_2021/batdetect/trial_data_2021/MSD-Z/Copy of 20220325_210000.WAV\n",
      "File processed in 4 seconds\n",
      "\n",
      "1     Copy of 20220325_212600.WAV\n",
      "Saving results to_/home/jupyter/gcs_outputs/trial_data_2021/batdetect/trial_data_2021/MSD-Z/Copy of 20220325_212600.WAV\n",
      "File processed in 4 seconds\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model, params = du.load_model(args['model_url'], args['model_path'])\n",
    "\n",
    "# load files\n",
    "files = du.get_audio_files(args['audio_dir'] )\n",
    "error_files = []\n",
    "\n",
    "for ii, audio_file in enumerate(tqdm(files, total = len(files))):\n",
    "    t1 = int(time.time())\n",
    "\n",
    "    print('\\n' + str(ii).ljust(6) + os.path.basename(audio_file))\n",
    "    try:\n",
    "        results = du.process_file(audio_file, model, params, args)\n",
    "        if args['save_preds_if_empty'] or (len(results['pred_dict']['annotation']) > 0):\n",
    "            msd = os.path.basename(os.path.dirname(audio_file))\n",
    "            project = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(audio_file))))\n",
    "            results_path = os.path.join(args['ann_dir'], project, msd, os.path.basename(audio_file))\n",
    "            print(\"Saving results to_\" + results_path)\n",
    "            du.save_results_to_file(results, results_path)\n",
    "            \n",
    "        t2 = int(time.time())\n",
    "        print('File processed in ' + str(t2 - t1) + ' seconds')\n",
    "    \n",
    "    except:\n",
    "        error_files.append(audio_file)\n",
    "        print(\"Error processing file!\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a684091-e5fc-4482-9c0c-9ee2eea79aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Copy of 20220325_212600.WAV\n",
      "1 calls detected\n",
      "\n",
      "time\tprob\tlfreq\tspecies_name\n",
      "18.3115\t0.245\t23750\tNyctalus leisleri\n"
     ]
    }
   ],
   "source": [
    "# print summary info for the individual detections \n",
    "print('Results for ' + results['pred_dict']['id'])\n",
    "print('{} calls detected\\n'.format(len(results['pred_dict']['annotation'])))\n",
    "\n",
    "print('time\\tprob\\tlfreq\\tspecies_name')\n",
    "for ann in results['pred_dict']['annotation']:\n",
    "    print('{}\\t{}\\t{}\\t{}'.format(ann['start_time'], ann['class_prob'], ann['low_freq'], ann['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3415304-a019-40a8-b98d-581b98694964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
